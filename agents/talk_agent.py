import os
import json
import re
from dataclasses import dataclass
from typing import List, Literal, Optional
from pydantic_ai import Agent, RunContext
from utils.llm import chat_model
from utils.tts import (
    generate_sentence_audio_and_srt, 
    merge_audio_files, 
    merge_srt_files
)


@dataclass
class TalkAgentDeps:
    scene_id: int = 1  # åœºæ™¯ID


@dataclass
class TalkAgentOutput:
    text: str = ""
    voice_type: Literal["male", "female", "narrator"] = "narrator"


talk_agent = Agent(
    model=chat_model,
    deps_type=TalkAgentDeps,
    output_type=List[TalkAgentOutput],
)


@talk_agent.instructions
def analyze_voice_assignment(ctx: RunContext[TalkAgentDeps]) -> str:
    """ä¸ºå·²ç»åˆ‡åˆ†å¥½çš„å¥å­åˆ†é…éŸ³è‰²"""    
    return """
è¯·ä½ æŒ‰ç…§ä»¥ä¸‹çš„æµç¨‹è¿›è¡Œå·¥ä½œã€‚

1. è°ƒç”¨ parse_script_sentences å·¥å…·
2. æ ¹æ®å·¥å…·è¿”å›çš„æ•°ç»„ï¼Œéå†å¥å­æ•°ç»„ï¼Œä¸ºæ¯ä¸ªå¥å­åˆ†é…éŸ³è‰²

éŸ³è‰²åˆ†é…è§„åˆ™ï¼š
- **male**: ç”·æ€§è§’è‰²å¯¹è¯ã€ç”·æ€§å†…å¿ƒç‹¬ç™½ã€ä»¥ç”·æ€§è§†è§’çš„å†…å®¹
- **female**: å¥³æ€§è§’è‰²å¯¹è¯ã€å¥³æ€§å†…å¿ƒç‹¬ç™½ã€ä»¥å¥³æ€§è§†è§’çš„å†…å®¹  
- **narrator**: ç¯å¢ƒæè¿°ã€å™è¿°æ–‡å­—ã€æ— æ˜ç¡®æ€§åˆ«çš„å†…å®¹ã€å®¢è§‚æè¿°

è¯·ä¸ºæ¯ä¸ªå¥å­åˆ†é…åˆé€‚çš„éŸ³è‰²ç±»å‹ï¼Œç„¶åè°ƒç”¨ generate_audio_and_srt å·¥å…·ç”ŸæˆéŸ³é¢‘æ–‡ä»¶ã€‚
"""


@talk_agent.tool
def parse_script_sentences(ctx: RunContext[TalkAgentDeps]) -> str:
    """è¯»å–åœºæ™¯è„šæœ¬å¹¶åˆ‡åˆ†æˆå¥å­æ•°ç»„"""
    scene_id = ctx.deps.scene_id
    scenes_file = "output/scenes.json"
    
    if not os.path.exists(scenes_file):
        return f"âŒ åœºæ™¯æ–‡ä»¶ä¸å­˜åœ¨: {scenes_file}"
    
    try:
        with open(scenes_file, "r", encoding="utf-8") as f:
            scenes_data = json.load(f)
        
        # æŸ¥æ‰¾æŒ‡å®šåœºæ™¯
        for scene in scenes_data:
            if scene.get("scene_id") == scene_id:
                script = scene.get("script", "")
                if not script:
                    return f"âŒ åœºæ™¯ {scene_id} çš„è„šæœ¬å†…å®¹ä¸ºç©º"
                
                # ä½¿ç”¨æ™ºèƒ½åˆ‡åˆ†å‡½æ•°åˆ‡åˆ†å¥å­
                sentences = _smart_split_sentences(script)
                
                # æ›´æ–° deps ä¸­çš„å¥å­åˆ—è¡¨
                ctx.deps.sentences = sentences
                
                return f"""âœ… åœºæ™¯ {scene_id} è„šæœ¬åˆ‡åˆ†å®Œæˆ:

åŸæ–‡å­—ç¬¦æ•°: {len(script)}
åˆ‡åˆ†å¥å­æ•°: {len(sentences)}

å¥å­åˆ—è¡¨:
{chr(10).join([f"{i+1}. {sentence}" for i, sentence in enumerate(sentences)])}

è¯·ä¸ºæ¯ä¸ªå¥å­åˆ†é…åˆé€‚çš„éŸ³è‰²ç±»å‹ï¼ˆmale/female/narratorï¼‰ï¼Œç„¶åè°ƒç”¨ generate_audio_and_srt å·¥å…·ã€‚"""
        
        return f"âŒ æœªæ‰¾åˆ°åœºæ™¯ {scene_id} çš„æ•°æ®"
        
    except Exception as e:
        return f"âŒ è¯»å–å’Œåˆ‡åˆ†åœºæ™¯æ–‡ä»¶å¤±è´¥: {str(e)}"


def _smart_split_sentences(text: str) -> List[str]:
    """æ™ºèƒ½åˆ‡åˆ†å¥å­ï¼Œè¯†åˆ«å¯¹è¯ã€å†…å¿ƒç‹¬ç™½å’Œå™è¿°"""
    sentences = []
    
    # é¢„å¤„ç†ï¼šå¤„ç†å¼•å·å†…çš„å†…å®¹
    parts = re.split(r'([""ã€ã€ã€Œã€][^""ã€ã€ã€Œã€]*[""ã€ã€ã€Œã€])', text)
    
    current_text = ""
    
    for part in parts:
        if not part.strip():
            continue
            
        # å¦‚æœæ˜¯å¼•å·å†…å®¹ï¼Œä½œä¸ºä¸€ä¸ªæ•´ä½“å¤„ç†
        if re.match(r'^[""ã€ã€ã€Œã€].*[""ã€ã€ã€Œã€]$', part.strip()):
            if current_text.strip():
                # å…ˆå¤„ç†ä¹‹å‰ç§¯ç´¯çš„æ–‡æœ¬
                temp_sentences = _split_by_punctuation(current_text)
                sentences.extend(temp_sentences)
                current_text = ""
            
            # å¼•å·å†…å®¹ä½œä¸ºç‹¬ç«‹å¥å­
            quote_content = part.strip()
            if quote_content:
                sentences.append(quote_content)
        else:
            current_text += part
    
    # å¤„ç†å‰©ä½™çš„æ–‡æœ¬
    if current_text.strip():
        temp_sentences = _split_by_punctuation(current_text)
        sentences.extend(temp_sentences)
    
    # æ¸…ç†å’Œä¼˜åŒ–å¥å­
    cleaned_sentences = []
    for sentence in sentences:
        sentence = sentence.strip()
        if sentence and len(sentence) > 1:  # è¿‡æ»¤æ‰å•å­—ç¬¦å’Œç©ºå¥å­
            # å¦‚æœå¥å­å¤ªé•¿ï¼ˆè¶…è¿‡60å­—ï¼‰ï¼Œå°è¯•è¿›ä¸€æ­¥åˆ‡åˆ†
            if len(sentence) > 60:
                sub_sentences = _split_long_sentence(sentence)
                cleaned_sentences.extend(sub_sentences)
            else:
                cleaned_sentences.append(sentence)
    
    return cleaned_sentences


def _split_by_punctuation(text: str) -> List[str]:
    """æŒ‰æ ‡ç‚¹ç¬¦å·åˆ‡åˆ†æ–‡æœ¬"""
    sentences = []
    current = ""
    
    for char in text:
        current += char
        if char in 'ã€‚ï¼ï¼Ÿ':
            if current.strip():
                sentences.append(current.strip())
            current = ""
    
    # å¤„ç†æœ€åæ²¡æœ‰æ ‡ç‚¹çš„éƒ¨åˆ†
    if current.strip():
        sentences.append(current.strip())
    
    return sentences


def _split_long_sentence(sentence: str) -> List[str]:
    """åˆ‡åˆ†è¿‡é•¿çš„å¥å­"""
    if len(sentence) <= 60:
        return [sentence]
    
    # å°è¯•åœ¨é€—å·ã€åˆ†å·å¤„åˆ‡åˆ†
    parts = re.split(r'([ï¼Œï¼›ã€])', sentence)
    
    result = []
    current = ""
    
    for part in parts:
        if current and len(current + part) > 50:
            if current.strip():
                result.append(current.strip())
            current = part
        else:
            current += part
    
    if current.strip():
        result.append(current.strip())
    
    return result if result else [sentence]


@talk_agent.tool
def generate_audio_and_srt(ctx: RunContext[TalkAgentDeps], segments: List[TalkAgentOutput]) -> str:
    """ä¸ºåˆ†æåçš„å¥å­ç”ŸæˆéŸ³é¢‘å’Œå­—å¹•æ–‡ä»¶"""
    scene_id = ctx.deps.scene_id
    
    if not segments:
        return f"âŒ åœºæ™¯ {scene_id} æ²¡æœ‰æœ‰æ•ˆçš„è¯­å¥æ®µè½"
    
    # éªŒè¯æ•°æ®
    valid_segments = []
    for seg in segments:
        if seg.text.strip():
            valid_segments.append((seg.text.strip(), seg.voice_type))
    
    if not valid_segments:
        return f"âŒ åœºæ™¯ {scene_id} æ²¡æœ‰æœ‰æ•ˆçš„æ–‡æœ¬å†…å®¹"
    
    try:
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        audio_dir = "output/audio"
        srt_dir = "output/srt"
        os.makedirs(audio_dir, exist_ok=True)
        os.makedirs(srt_dir, exist_ok=True)
        
        # ç”Ÿæˆæ¯ä¸ªå¥å­çš„éŸ³é¢‘å’Œå­—å¹•
        audio_files, srt_files = generate_sentence_audio_and_srt(
            valid_segments, 
            "output", 
            scene_id
        )
        
        if not audio_files:
            return f"âŒ åœºæ™¯ {scene_id} éŸ³é¢‘ç”Ÿæˆå¤±è´¥"
        
        # åˆå¹¶éŸ³é¢‘æ–‡ä»¶
        merged_audio_path = os.path.join(audio_dir, f"scene_{scene_id}.wav")
        audio_result = merge_audio_files(audio_files, merged_audio_path)
        
        # åˆå¹¶SRTæ–‡ä»¶
        merged_srt_path = os.path.join(srt_dir, f"scene_{scene_id}.srt")
        srt_result = merge_srt_files(srt_files, merged_srt_path)
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        for temp_file in audio_files + srt_files:
            try:
                if os.path.exists(temp_file):
                    os.remove(temp_file)
            except Exception:
                pass
        
        # ç»Ÿè®¡éŸ³è‰²ä½¿ç”¨æƒ…å†µ
        voice_stats = {}
        for _, voice_type in valid_segments:
            voice_stats[voice_type] = voice_stats.get(voice_type, 0) + 1
        
        stats_str = ", ".join([f"{voice}: {count}å¥" for voice, count in voice_stats.items()])
        
        return f"""âœ… åœºæ™¯ {scene_id} éŸ³é¢‘å’Œå­—å¹•ç”Ÿæˆå®Œæˆ:

ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:
- å¥å­æ€»æ•°: {len(valid_segments)}
- éŸ³è‰²åˆ†å¸ƒ: {stats_str}

ğŸ“ è¾“å‡ºæ–‡ä»¶:
- éŸ³é¢‘: {merged_audio_path}
- å­—å¹•: {merged_srt_path}

ğŸ”§ å¤„ç†ç»“æœ:
- {audio_result}
- {srt_result}"""
        
    except Exception as e:
        return f"âŒ ç”ŸæˆéŸ³é¢‘å’Œå­—å¹•å¤±è´¥: {str(e)}"